基于keras的轻量级bert
https://github.com/bojone/bert4keras

ALbert模型的实现
https://link.zhihu.com/?target=https%3A//github.com/brightmart/albert_zh

使用PaddlePaddle做词向量skip-gram
http://www.360doc.com/content/19/0816/04/46368139_855209381.shtml

bert for tf2.0
https://github.com/kpe/bert-for-tf2

adapter-bert的地址
https://github.com/google-research/adapter-bert/

bert作为服务应用
https://github.com/hanxiao/bert-as-service

Skip-Thought Vectors
https://arxiv.org/pdf/1506.06726.pdf

BioBERT: 用于生物医学文本挖掘的预先训练生物医学语言表示模型
fine-tuning代码
https://github.com/dmis-lab/biobert
BioBERT预训练模型权重下载
https://github.com/naver/biobert-pretrained
BioBERT论文解读
https://blog.csdn.net/devshilei/article/details/103887864

Bert可视化工具bertviz
https://github.com/jessevig/bertviz
https://blog.csdn.net/duan_zhihua/article/details/87388646

BERT论文合集
https://github.com/tomohideshibata/BERT-related-papers#domain-specific

全面剖析Transformer
https://jalammar.github.io/illustrated-transformer/

Transformer
https://arxiv.org/abs/1706.03762.pdf
tensorflow版本：https://github.com/tensorflow/tensor2tensor
pytorch版本：http://nlp.seas.harvard.edu/2018/04/03/attention.html

Transformer-XL
https://arxiv.org/pdf/1901.02860.pdf
https://github.com/kimiyoung/transformer-xl







# Transformer
- 1706: [Transformer Paper](https://arxiv.org/abs/1706.03762.pdf). [tensorflow version](https://github.com/tensorflow/tensor2tensor) and [pytorch version](http://nlp.seas.harvard.edu/2018/04/03/attention.html). [Analysis transformer in detail](https://jalammar.github.io/illustrated-transformer/)  
- [Transformer代码完全解读！](https://blog.csdn.net/Datawhale/article/details/120320116?spm=1001.2101.3001.6650.11&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7ERate-11.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7ERate-11.pc_relevant_default&utm_relevant_index=12)  
# Transformer Variant
- 1901: [Transformer-XL](https://github.com/kimiyoung/transformer-xl) (from google) released with the paper [Transformer-XL: Attentive Language Models
Beyond a Fixed-Length Context](https://arxiv.org/pdf/1901.02860.pdf) by Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.
[CSDN blog](https://blog.csdn.net/magical_bubble/article/details/89060213)  




* 2006: [Funnel-Transformer](http://github.com/laiguokun/Funnel-Transformer) [Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing](https://arxiv.org/abs/2006.03236) by Zihang Dai (CMU, Google), Guokun Lai (CMU), Yiming Yang (CMU), Quoc V. Le (Google)

* 2009: [Performer](https://github.com/google-research/google-research/tree/master/performer) [Rethinking Attention with Performers](https://arxiv.org/pdf/2009.14794)[official website](https://www.aminer.cn/pub/5f75feb191e0111c1eb4dbb2/rethinking-attention-with-performers) by Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou SongAndreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin Lukasz Kaiser, David Belanger, Lucy Colwell, Adrian Weller

* 2012: [Informer]() [Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting](https://arxiv.org/pdf/2012.07436.pdf)

* : []() [DeepNet_ Scaling Transformers to 1,000 Layers]()

* CS25：  
视频链接：https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM  
课程主页：https://web.stanford.edu/class/cs25/  

* TorchScale（from MSRA）：https://github.com/microsoft/torchscale  



